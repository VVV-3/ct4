{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224dc9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.datasets import patientDataset, eegDataset\n",
    "# from src.resnet import ResNet1d\n",
    "# from src.lstm import Lstm\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import mne\n",
    "from helper_code import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf39cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "def psd(eeg_data, fs):\n",
    "    # Define frequency bands of interest (in Hz)\n",
    "    freq_bands = {'delta': [0.5, 4],\n",
    "              'theta': [4, 8],\n",
    "              'alpha': [8, 12],\n",
    "              'beta': [12, 30]}\n",
    "\n",
    "    # Define sampling frequency (in Hz)\n",
    "    fs = 60\n",
    "\n",
    "    # Compute PSD and extract power in each frequency band for each epoch\n",
    "    freqs, psds = signal.welch(eeg_data, fs=fs, nperseg=fs*2)\n",
    "    band_powers = {}\n",
    "    for band, freq_range in freq_bands.items():\n",
    "        freq_mask = (freqs >= freq_range[0]) & (freqs < freq_range[1])\n",
    "        band_powers[band] = psds[:, freq_mask]\n",
    "        \n",
    "    return np.concatenate([band_powers[band] for band in freq_bands])\n",
    "\n",
    "def bsr(eeg_data, sfreq):\n",
    "    epoch_duration = 1\n",
    "    freq_band = [0.5, 25]\n",
    "    bsr_threshold = 0.5\n",
    "    nyquist_freq = sfreq / 2\n",
    "    b, a = signal.butter(4, [freq_band[0] / nyquist_freq, freq_band[1] / nyquist_freq], btype='bandpass')\n",
    "    filtered_data = signal.filtfilt(b, a, eeg_data)\n",
    "\n",
    "    epoch_samples = int(epoch_duration * sfreq)\n",
    "    n_epochs = filtered_data.shape[-1] // epoch_samples\n",
    "    epochs = filtered_data[:, :n_epochs * epoch_samples].reshape(18, n_epochs, epoch_samples)\n",
    "    \n",
    "    rms_amplitude = np.sqrt(np.mean(epochs ** 2, axis=-1))\n",
    "    median_rms = np.median(rms_amplitude)\n",
    "    bsr = (rms_amplitude < bsr_threshold * median_rms).mean(axis=-1) * 100\n",
    "    return bsr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d56fae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from helper_code import *\n",
    "import numpy as np, os, sys\n",
    "import librosa\n",
    "import mne\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "n_mels = 256\n",
    "n_mfcc = 256\n",
    "\n",
    "\n",
    "def featurise_recording(location):\n",
    "    channels = ['Fp1-F7', 'F7-T3', 'T3-T5', 'T5-O1', 'Fp2-F8', 'F8-T4', \n",
    "                'T4-T6', 'T6-O2', 'Fp1-F3', 'F3-C3', 'C3-P3', 'P3-O1', \n",
    "                'Fp2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'Fz-Cz', 'Cz-Pz']\n",
    "    recording_data, sr, cur_channels = load_recording(location)\n",
    "    signal_data = reorder_recording_channels(recording_data, cur_channels, channels)\n",
    "    \n",
    "    resampled_data = librosa.resample(y=signal_data, orig_sr=sr, target_sr=60)\n",
    "    resampled_data = resampled_data[:, 120*60: 140*60]\n",
    "#     final2 = psd(resampled_data, 60)\n",
    "    final1 = bsr(resampled_data, 60)\n",
    "#     final3 = dwt(resampled_data, 60)\n",
    "    \n",
    "    final = np.concatenate((final1, final2))\n",
    "#     print(final.shape)\n",
    "    \n",
    "    return final\n",
    "\n",
    "def featurise_locs(locs):\n",
    "    fin = []\n",
    "    fin.append(featurise_recording(locs[0]))\n",
    "    fin.append(featurise_recording(locs[len(locs)//2]))\n",
    "    fin.append(featurise_recording(locs[-1]))\n",
    "    fin = np.array(fin).flatten()\n",
    "#     print(fin.shape)\n",
    "    return fin\n",
    "\n",
    "def featurise_labels(label):\n",
    "#     print(label)\n",
    "    tp = np.array([0,0])\n",
    "    tp[label] = 1\n",
    "    return tp\n",
    "\n",
    "class patientDataset(Dataset):\n",
    "    def __init__(self, data_folder, segs):\n",
    "        \n",
    "        self.no_of_segments = segs\n",
    "        \n",
    "        self.data_folder  = data_folder\n",
    "        self.patient_ids  = find_data_folders(data_folder)\n",
    "        self.num_patients = len(self.patient_ids)\n",
    "        \n",
    "        self.inputs = []\n",
    "        self.outcomes = []\n",
    "        \n",
    "        for i in tqdm(range(self.num_patients)):\n",
    "            inp, out = self.getitemx(i)\n",
    "#             if inp.shape[0] == self.no_of_segments:\n",
    "            self.inputs.append(inp)\n",
    "            self.outcomes.append(out)\n",
    "#         self.inputs = np.array(self.inputs)\n",
    "#         self.outcomes = np.array(self.outcomes)\n",
    "        \n",
    "    def getMetadata(self, idx):\n",
    "        # Load data.\n",
    "        patient_id = self.patient_ids[idx]\n",
    "        \n",
    "        # Define file location.\n",
    "        patient_metadata_file = os.path.join(self.data_folder, patient_id, patient_id + '.txt')\n",
    "        recording_metadata_file = os.path.join(self.data_folder, patient_id, patient_id + '.tsv')\n",
    "\n",
    "        # Load non-recording data.\n",
    "        patient_metadata = load_text_file(patient_metadata_file)\n",
    "        recording_metadata = load_text_file(recording_metadata_file)\n",
    "        \n",
    "        return patient_metadata, recording_metadata\n",
    "        \n",
    "    def getitemx(self, index):\n",
    "        \n",
    "        patient_metadata, recording_metadata = self.getMetadata(index)\n",
    "        \n",
    "        # Load recordings.\n",
    "        recording_ids = list(get_recording_ids(recording_metadata))\n",
    "        \n",
    "        recording_locations = []\n",
    "        for recording_id in reversed(recording_ids):\n",
    "            if recording_id != 'nan':\n",
    "                recording_location = os.path.join(self.data_folder, self.patient_ids[index], recording_id)\n",
    "                recording_locations.append(recording_location)\n",
    "            \n",
    "            if len(recording_locations) >= self.no_of_segments:\n",
    "                break\n",
    "        recording_locations.reverse()\n",
    "        print(len(recording_locations), get_outcome(patient_metadata))\n",
    "        return featurise_locs(recording_locations), featurise_labels(get_outcome(patient_metadata))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.inputs[index], self.outcomes[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25c2d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import numpy as np\n",
    "\n",
    "def dwt(eeg_signal, sfreq):\n",
    "    eeg_signal = eeg_signal[:, 170*sfreq:180*sfreq]\n",
    "    # Define the wavelet family and level of decomposition\n",
    "    wavelet = 'db4'\n",
    "    level = 5\n",
    "\n",
    "    # Compute the wavelet coefficients for each channel\n",
    "    coeffs_list = []\n",
    "    for ch_signal in eeg_signal:\n",
    "        coeffs = pywt.wavedec(ch_signal, wavelet, level=level)\n",
    "        coeffs_list.append(coeffs)\n",
    "\n",
    "    # Extract the coefficients corresponding to each frequency band for each channel\n",
    "    delta_coeffs_list = []\n",
    "    theta_coeffs_list = []\n",
    "    alpha_coeffs_list = []\n",
    "    beta_coeffs_list = []\n",
    "    for coeffs in coeffs_list:\n",
    "        delta_coeffs = coeffs[level]\n",
    "        theta_coeffs = coeffs[level-1]\n",
    "        alpha_coeffs = coeffs[level-2]\n",
    "        beta_coeffs = coeffs[level-3]\n",
    "        delta_coeffs_list.append(delta_coeffs)\n",
    "        theta_coeffs_list.append(theta_coeffs)\n",
    "        alpha_coeffs_list.append(alpha_coeffs)\n",
    "        beta_coeffs_list.append(beta_coeffs)\n",
    "\n",
    "    # Stack the coefficient arrays for each frequency band across channels\n",
    "    delta_coeffs = np.stack(delta_coeffs_list, axis=0)\n",
    "    theta_coeffs = np.stack(theta_coeffs_list, axis=0)\n",
    "    alpha_coeffs = np.stack(alpha_coeffs_list, axis=0)\n",
    "    beta_coeffs = np.stack(beta_coeffs_list, axis=0)\n",
    "    \n",
    "    fin = np.concatenate( (delta_coeffs, theta_coeffs, alpha_coeffs, beta_coeffs), axis=1 ).mean(axis=0)\n",
    "#     print(fin.shape)\n",
    "    return fin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59622179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/486 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 0\n",
      "(18, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'final2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m no_of_segs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m82\u001b[39m\n\u001b[0;32m----> 5\u001b[0m pattrainset \u001b[38;5;241m=\u001b[39m \u001b[43mpatientDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../train/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_of_segs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m pattestset \u001b[38;5;241m=\u001b[39m patientDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../split_5/\u001b[39m\u001b[38;5;124m\"\u001b[39m, no_of_segs)\n\u001b[1;32m      9\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 63\u001b[0m, in \u001b[0;36mpatientDataset.__init__\u001b[0;34m(self, data_folder, segs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutcomes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_patients)):\n\u001b[0;32m---> 63\u001b[0m             inp, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetitemx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#             if inp.shape[0] == self.no_of_segments:\u001b[39;00m\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mappend(inp)\n",
      "Cell \u001b[0;32mIn[11], line 101\u001b[0m, in \u001b[0;36mpatientDataset.getitemx\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     99\u001b[0m recording_locations\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(recording_locations), get_outcome(patient_metadata))\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeaturise_locs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecording_locations\u001b[49m\u001b[43m)\u001b[49m, featurise_labels(get_outcome(patient_metadata))\n",
      "Cell \u001b[0;32mIn[11], line 37\u001b[0m, in \u001b[0;36mfeaturise_locs\u001b[0;34m(locs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeaturise_locs\u001b[39m(locs):\n\u001b[1;32m     36\u001b[0m     fin \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 37\u001b[0m     fin\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfeaturise_recording\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     38\u001b[0m     fin\u001b[38;5;241m.\u001b[39mappend(featurise_recording(locs[\u001b[38;5;28mlen\u001b[39m(locs)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m     39\u001b[0m     fin\u001b[38;5;241m.\u001b[39mappend(featurise_recording(locs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "Cell \u001b[0;32mIn[11], line 30\u001b[0m, in \u001b[0;36mfeaturise_recording\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m     27\u001b[0m     final1 \u001b[38;5;241m=\u001b[39m bsr(resampled_data, \u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#     final3 = dwt(resampled_data, 60)\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     final \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((final1, \u001b[43mfinal2\u001b[49m))\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#     print(final.shape)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final2' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "no_of_segs = 82\n",
    "pattrainset = patientDataset(\"../train/\", no_of_segs)\n",
    "\n",
    "pattestset = patientDataset(\"../split_5/\", no_of_segs)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf4a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset=pattrainset, batch_size=32, shuffle=True, num_workers=20)\n",
    "valloader = DataLoader(dataset=pattestset, batch_size=32, shuffle=True, num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4002a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(pattrainset.inputs), np.array(pattrainset.outcomes)\n",
    "# X = X.reshape((X.shape[0], X.shape[1]*X.shape[2]))\n",
    "y = y[:,0]\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3420a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(X)\n",
    "df['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969fe19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "# We will be using default parameter Here with H2O init method\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316cccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas DataFrame into H2O Frame\n",
    "train = h2o.H2OFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de62d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(pattrainset.inputs), np.array(pattrainset.outcomes)\n",
    "# X = X.reshape((X.shape[0], X.shape[1]*X.shape[2]))\n",
    "y = y[:,0]\n",
    "df_val = pd.DataFrame(X)\n",
    "df_val['y'] = y\n",
    "\n",
    "test = h2o.H2OFrame(df_val)\n",
    "x = test.columns\n",
    "y = 'y'\n",
    "# remove label classvariable from feature variable\n",
    "x.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fc98e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For binary classification, response should be a factor\n",
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()\n",
    "\n",
    "# Run AutoML for 20 base models\n",
    "aml = H2OAutoML(max_models=20, seed=1)\n",
    "aml.train(y = y, training_frame = train, leaderboard_frame = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffafc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e561da",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = aml.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea2738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['p1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3262e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion):\n",
    "    val_loss = []\n",
    "    val_accs = []\n",
    "    model.eval()\n",
    "    for i, (inputs, labels) in enumerate(val_loader):\n",
    "        inputs = torch.Tensor(inputs)\n",
    "        inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "        labels = torch.Tensor(labels)\n",
    "        labels = labels.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss    = criterion(outputs, labels)\n",
    "        pred, lab = torch.argmax(outputs, axis=-1), torch.argmax(labels, axis=-1)\n",
    "        \n",
    "        val_loss.append(loss.item())\n",
    "        val_accs.append( ((pred == lab).sum()/ len(pred)).cpu().detach().numpy() )\n",
    "    \n",
    "    return np.mean(val_loss), np.mean(val_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f1304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, criterion ,train_loader, epoch):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    for i, (inputs, labels) in enumerate(train_loader): \n",
    "            \n",
    "        inputs = torch.Tensor(inputs)\n",
    "        inputs = inputs.type(torch.FloatTensor).to(device)\n",
    "        labels = torch.Tensor(labels)\n",
    "        labels = labels.type(torch.FloatTensor).to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "#         print(outputs.shape, labels.shape)\n",
    "        loss    = criterion(outputs, labels)\n",
    "        \n",
    "        pred, lab = torch.argmax(outputs, axis=-1), torch.argmax(labels, axis=-1)\n",
    "#         print(pred, lab)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.cpu().detach().numpy())\n",
    "        train_acc.append( ((pred == lab).sum()/ len(pred)).cpu().detach().numpy() )\n",
    "        print(\"Epoch {}: {}/{} Loss: {}  Acc: {}\".format(epoch, i, len(train_loader), loss.item(), train_acc[-1]), end='\\r')\n",
    "        \n",
    "    return np.mean(train_loss), np.mean(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea67545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Lstm(nn.Module):\n",
    "    \"\"\"lstm+mlp\"\"\"\n",
    "    def __init__(self, inp_dim, hidden_dim, target_size=2, num_layers=1):\n",
    "        super(Lstm, self).__init__()\n",
    "        self.lstm = nn.LSTM(inp_dim, hidden_dim)\n",
    "        self.mlp  = nn.Linear(hidden_dim, target_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, hidden = self.lstm( x )\n",
    "        x = self.mlp(x)\n",
    "        return x.flatten()\n",
    "    \n",
    "class FNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc0 = nn.Linear(2019, 1024)\n",
    "        self.fc1 = nn.Linear(1024, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc0(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e911894",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = { 'num_epochs':20, 'learning_rate':1e-4 }\n",
    "arch_config  = {\n",
    "                'inp_size': 90,\n",
    "                'hidden_size': 180,\n",
    "               }\n",
    "\n",
    "model = Lstm(arch_config[\"inp_size\"], arch_config[\"hidden_size\"])\n",
    "model = FNN()\n",
    "model = model.to(device)\n",
    "# model = torch.compile(model)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=train_config['learning_rate'], weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(train_config['num_epochs']):\n",
    "    los, acc = train_one_epoch(model, optimizer, criterion, trainloader, epoch)\n",
    "    train_losses.append(los)\n",
    "    train_accs.append(acc)\n",
    "    los, acc = validate(model, valloader, criterion)\n",
    "    val_losses.append(los)\n",
    "    val_accs.append(acc)\n",
    "    print(train_losses[-1], val_losses[-1], train_accs[-1], val_accs[-1])\n",
    "    if epoch % 10 == 0:\n",
    "        plt.plot(train_losses, label=\"train loss\")\n",
    "        plt.plot(val_losses, label=\"val loss\")\n",
    "        plt.plot(train_accs, label=\"train acc\")\n",
    "        plt.plot(val_accs, label=\"val acc\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266e0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train loss\")\n",
    "plt.plot(val_losses, label=\"val loss\")\n",
    "plt.plot(train_accs, label=\"train acc\")\n",
    "plt.plot(val_accs, label=\"val acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2ec7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
